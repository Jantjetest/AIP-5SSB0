{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Theory Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries\n",
    "\n",
    "- Goal \n",
    "  - Review of probability theory from a logical viewpoint (i.e., a Bayesian interpretation)\n",
    "- Materials        \n",
    "  - Mandatory\n",
    "    - These lecture notes\n",
    "  - Optional\n",
    "    - Bishop pp. 12-20       \n",
    "    - [Bruininkx - 2002 - Bayesian Probability](./files/Bruyninkx-2002-Bayesian-probability.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Probability Theory?\n",
    "\n",
    "- Probability theory (PT) is the **theory of optimal processing of incomplete information**, and as such provides a quantitative framework for drawing conclusions from a finite (read: incomplete) data set.\n",
    "- Machine learning concerns drawing conclusions from data.\n",
    "- In general, nearly all interesting questions in machine learning can be stated in the following form (a conditional probability):\n",
    "\n",
    "$$p(\\text{whatever-we-want-to-know}\\, | \\,\\text{whatever-we-do-know})$$\n",
    "\n",
    "- For example\n",
    "  - Generate data predictions, $p(x_{\\text{future}}|x_{\\text{past}})$\n",
    "  - Classify a received data point, $p(\\mathcal{C}_k|x)$\n",
    "  - Compress data in an efficient way from $p(x_n|x_{1:n-1})$\n",
    "\n",
    "- Note that **Information theory** (the \"theory of log-probability\") provides a source coding view on machine learning that is consistent with probability theory (more in part-2). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Probability Theory Notation\n",
    "-  An **event** $A$ is a statement, whose truth is contemplated by a person, e.g.,\n",
    "\n",
    "$$A = \\text{`it will rain tomorrow'}$$\n",
    " \n",
    "- Notation: $\\bar{A}$ (latex: \\bar{A}) is **not**-A, the denial of statement $A$\n",
    "- For any event $A$, with background knowledge $I$, the **probability of $A$, given $I$** is written as \n",
    "$$p(A|I)$$\n",
    "which is a number between $0$ and $1$. If, given $I$, you know that $A$ is true, than $p(A|I)=1$.\n",
    "\n",
    "- The probability $p(A|I)$ should be **interpreted as your degree of belief** that event $A$ is true, given that $I$ is true. This is an extremely powerful interpretation (later more about this). \n",
    "\n",
    "Notation for compound events:\n",
    "\n",
    "- $p(A,B|I)$ or $$is the **joint** probability that both $A$ and $B$ are true, given $I$.\n",
    "- $p(A+B|I)$ is the probability that either $A$ or $B$, or both $A$ and $B$, are true, given $I$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Probability Theory Calculus\n",
    " \n",
    "Probability theory **extends** boolean logic to rational reasoning with uncertainty. Under some mild conditions, the following calculation rules can be derived, (see [Cox, 1946](https://en.wikipedia.org/wiki/Cox%27s_theorem)):\n",
    " \n",
    "- **Product rule**. For 2 events $A, B$ with given background $I$,\n",
    "\n",
    "$$ p(A,B|I) = p(A|B,I)\\,p(B|I) \\,.$$\n",
    "\n",
    "- **Sum rule**. For 2 events $A$, $B$ with given background $I$,\n",
    "\n",
    "$$ p(A+B|I) = p(A|I) + p(B|I) - p(A,B|I)\\,.$$\n",
    "\n",
    "- Clearly, it follows from the sum rule that $ p(A|I) + p(\\bar{A}|I) = 1$\n",
    "\n",
    "- Note that the background information may not change, e.g., if $I^\\prime \\neq I$, then \n",
    "\n",
    "$$p(A,B|I) \\neq p(A|B,I)\\,p(B|I^\\prime)$$ \n",
    "\n",
    "- **All legitimate relations between probabilities can be derived from the sum and product rules!!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Notation and useful facts\n",
    "\n",
    "- Iff \n",
    "$$p(A,B|I) = p(A|I)p(B|I)$$\n",
    "then $A$ and $B$ are said to be **independent**, given $I$. Note that this is equivalent to the statement $p(A|B,I)=p(A|I)$.\n",
    "\n",
    "- The product and sum rules are also known as the **axioms of probability theory**, but in fact they can be derived as the unique rules for rational reasoning under uncertainty.\n",
    "- All probabilities are in principle conditional probabilities of the type $p(A|I)$, since there is always some background knowledge. \n",
    " \n",
    "- Shorthand notation\n",
    "  - Still, we often write $p(A)$ rather than $p(A|I)$ if the background knowledge $I$ is assumed to be obviously present. E.g., $p(X=5)$ rather than $p(X=5|\\text{the sun comes up tomorrow})$.    \n",
    "  - If $X$ is a random variable and $X=x$ is an event, then we often write $p(x)$ rather than $p(X=x)$ (hoping again that the reader understands the context ;-)  \n",
    "  - $p(X)$ denotes the distribution over random variable $X$.   \n",
    "\n",
    "- Next, we present two useful corollaries:  (1) Marginalization and (2) Bayes rule \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Sum Rule and Marginalization\n",
    "- If $X$ and $Y$ are random variables, than it follows from the sum rule that \n",
    "\n",
    "$$p(X) = \\sum_Y p(X,Y) \\left( = \\sum_Y p(X|Y)p(Y) \\right)$$ \n",
    "\n",
    "- Note that Bishop (p.14) calls this the sum rule.\n",
    "\n",
    "- Proof this!\n",
    "\n",
    "- Of course, in the continuous domain, $p(x)=\\int p(x,y) \\mathrm{d}y$\n",
    "\n",
    "- Integrating $Y$ out of a joint distribution is called **marginalization** and the result $p(X)$ is sometimes referred to as the **marginal probability**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### The Product Rule and Bayes Rule\n",
    "\n",
    "- Consider 2 variables $D$ and $\\theta$; it follows from $p(D,\\theta)=p(D|\\theta)p(\\theta)=p(\\theta|D)p(D)$ that\n",
    "\n",
    "$$ p(\\theta|D) = \\frac{p(D|\\theta) p(\\theta)}{p(D)}$$ \n",
    "\n",
    "- This formula is called **Bayes rule**. While Bayes rule is always true, a particularly useful application occurs when $D$ refers to an observed data set and $\\theta$ is set of model parameters that relates to the data. In that case,\n",
    "\n",
    "  - the **prior** probability $p(\\theta)$ represents our **degree-of-belief** about proper values for $\\theta$, before seeing the data $D$.\n",
    "  - the **posterior** probability $p(\\theta|D)$ relates to our state-of-knowledge about $\\theta$ after we have seen the data.\n",
    "\n",
    "$\\Rightarrow$ Bayes rule tells us how to update our knowledge about model parameters (or other hypotheses) when facing new data. Hence, \n",
    "\n",
    "<center>\n",
    "<div style=\"border:2px solid blue;padding:1em;\">\n",
    "**Bayes rule is the fundamental rule for machine learning!**\n",
    "</div>\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes Rule Nomenclature\n",
    "- Some nomenclature associated with Bayes rule\n",
    "$$\\begin{equation}\n",
    "\\underbrace{p(\\theta | D)}_{\\text{posterior}} = \\frac{\\overbrace{p(D|\\theta)}^{\\text{likelihood}} \\times \\overbrace{p(\\theta)}^{\\text{prior}}}{\\underbrace{p(D)}_{\\text{evidence}}}\n",
    "\\end{equation}$$\n",
    "\n",
    "- Note that the evidence can be computed through marginalization since\n",
    "$$ p(D) = \\int p(D,\\theta) \\,\\mathrm{d}\\theta = \\int p(D|\\theta)\\,p(\\theta) \\,\\mathrm{d}\\theta$$\n",
    "\n",
    "- For given $D$, the posterior probabilities of the parameters scale relatively against each other as\n",
    "$$\n",
    "p(\\theta|D) \\propto p(D|\\theta) p(\\theta)\n",
    "$$\n",
    "\n",
    "$\\Longrightarrow$ All that we can learn from the observed data is contained in the likelihood function $p(D|\\theta)$. This is called the **likelihood principle**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Likelihood Function\n",
    "\n",
    "Consider a probabilistic model $p(D|\\theta)$, where $D$ relates to a data set and $\\theta$ are model parameters.\n",
    "\n",
    "- In general, $p(D|\\theta)$ is a function of both $D$ and $\\theta$.\n",
    "\n",
    "- The **sampling distribution** $$p(D|\\theta=\\theta_0)$$ describes the probability that data $D$ is observed, assuming that it is generated by the given model with parameter values set to $\\theta = \\theta_0$.\n",
    "\n",
    "- In a machine learning context, often $D=D_0$ is given (observed), and $\\theta$ is the free variable.\n",
    "\n",
    "- When viewed as a function of the free variable $\\theta$ with given $D=D_0$, $$\\mathrm{L}(\\theta) \\triangleq p(D=D_0|\\theta)$$ is called the **likelihood function** (for $\\theta$)\n",
    "\n",
    "- Note that $\\mathrm{L}(\\theta)$ is not a probability distribution for $\\theta$.  (Is $\\sum_\\theta \\mathrm{L}(\\theta)=1$ always true?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MARCO - DO AN EXAMPLE IN JULIA THAT SHOWS THE DIFFERENCE OF THE SAMPLING DISTRIBUTION AND TE LIKELIHOOD FUNCTION FOR THE SAME PRESCRIPTION $p(D|\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Probabilistic Inference\n",
    "-- **Probabilistic inference** is computing\n",
    "\n",
    "$$\n",
    "p(\\text{whatever-we-want-to-know}\\, | \\,\\text{whatever-we-do-know})\n",
    "$$\n",
    "\n",
    "E.g., \n",
    "\n",
    "   $p(\\,\\text{Mr.S. killed Mrs.S.} \\;|\\; \\text{evidence}\\,),$\n",
    "\n",
    "   $p(\\,\\text{transmitted codeword} \\;|\\;\\text{received codeword}\\,),$\n",
    "\n",
    "   $p(\\,\\text{articulatory movements} \\;|\\; \\text{speech signal}\\,),$\n",
    "\n",
    "   $p(\\,\\text{fetal HR signal} \\;|\\;\\text{mother signal}\\,).$\n",
    "                \n",
    "- This can be accomplished by repeated application of sum and product rules, (of course).\n",
    "\n",
    "- In practice, Bayes Rule and  marginalization are very useful tools.\n",
    "\n",
    "- The resulting expressions often contain a bunch of (hard) integrals and/or sums (with many terms).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Exercise: Disease Diagnosis\n",
    "\n",
    "[Q.] Given a disease $D$ with prevalence of $1\\%$ and a test procedure $T$ with sensitivity ('true positive' rate) of $95\\%$ and specificity ('true negative' rate) of $85\\%$, what is the chance that somebody who tests positive actually has the disease?\n",
    "\n",
    "[A.] The given data are $p(D=1)=0.01$, $p(T=1|D=1)=0.95$ and $p(T=0|D=0)=0.85$. Then according to Bayes rule,\n",
    "\n",
    "$$\\begin{align*}\n",
    "p( & D=1 | T=1) \\\\\n",
    "&= \\frac{p(T=1|D=1)p(D=1)}{p(T=1)} \\tag{Bayes}\\\\\n",
    "&= \\frac{p(T=1|D=1)p(D=1)}{p(T=1|D=1)p(D=1)+p(T=1|D=0)p(D=0)} \\tag{marg.}\\\\\n",
    "&= \\frac{0.95\\times0.01}{0.95\\times0.01 + 0.15\\times0.99} = 0.0601\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Inference Exercise: Bag Counter\n",
    "[Q.] A bag contains one ball, known to be either white or black. A white ball is put in, the bag is shaken,\n",
    " and a ball is drawn out, which proves to be white. What is now the\n",
    " chance of drawing a white ball?\n",
    "\n",
    "[A.]  Again, use Bayes and marginalization to arrive at $p(\\text{white}|\\text{data})=2/3$, see homework exercise\n",
    "\n",
    "$\\Rightarrow$ Note that probabilities describe **a person's state of knowledge** rather than a 'property of nature'.\n",
    "\n",
    "[Q.] Is a speech signal a 'probabilistic' (random) variable? (homework)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Inference Exercise: Causality?\n",
    "\n",
    "[Q.] A dark bag contains five red balls and seven green ones. (a) What is the probability of drawing a red ball on the first draw? Balls are not returned to the bag after each draw. (b) If you know that on the second draw the ball was a green one, what is now the probability of drawing a red ball on the first draw?\n",
    "\n",
    "[A.] (a) $5/12$. (b) $5/11$, see homework.\n",
    "\n",
    "$\\Rightarrow$ Again, we conclude that conditional probabilities reflect **implications for a state of knowledge** rather than temporal causality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### PDF for the Sum of Two Variables\n",
    "\n",
    "[Q.]: Given two random **independent** variables\n",
    "$X$ and $Y$, with PDF's $p_x(x)$ and $p_y(y)$. What is the PDF\n",
    "of $Z = X + Y$?\n",
    "\n",
    "[A.]: Let $p_z(z)$ be the probability that $Z$ has value $z$. This occurs if $X$ has some value $x$ and at the same time $Y=z-x$, with joint probability $p_x(x)p_y(z-x)$. Since $x$ can be any value, we sum over all possible values for $x$ to get\n",
    "\n",
    "$$\n",
    "        p_z (z) = \\int_{ - \\infty }^\\infty  {p_x (x)p_y (z - x)\\,\\mathrm{d}{x}}\n",
    "$$\n",
    "        \n",
    "i.e., the **convolution** of $p_x$ and $p_y$.\n",
    "        \n",
    "Note that $p_z(z) \\neq p_x(x) + p_y(y)\\,$ !!\n",
    "\n",
    "$\\Rightarrow$ In linear stochastic systems theory, the Fourier Transform of a PDF (i.e., the characteristic function) plays an important computational role.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MARCO EXAMPLE IN JULIA WITH INTERACT CONTROLS FOR Z=X+Y and X and Y ARE GAUSSIAN ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Expectation and Variance\n",
    "\n",
    "- $\\mathrm{E}[f] \\equiv  \\int f(x) \\,p(x) \\,\\mathrm{d}{x}$, **expected value** or **mean**\n",
    "\n",
    "- $\\mathrm{var}[f] \\equiv \\mathrm{E} \\left[(f(x)-\\mathrm{E}[f(x)])^2 \\right]$, **variance**\n",
    "\n",
    "- The **covariance** between _vectors_ $x$ and $y$,\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathrm{cov}[x,y] &= \\mathrm{E}\\left[ (x-\\mathrm{E}[x]) (y^T-\\mathrm{E}[y^T]) \\right]\\\\\n",
    "    &= \\mathrm{E}[x y^T] - \\mathrm{E}[x]\\mathrm{E}[y^T]\n",
    "\\end{align*}\n",
    "\n",
    "-  Also useful as: $\\mathrm{E}[xy^T] = \\mathrm{cov}[x,y] + \\mathrm{E}[x]\\mathrm{E}[y^T]$\n",
    "\n",
    "\n",
    "### Linear Transformations\n",
    "\n",
    "No matter how $x$ is distributed, we can easily derive that **(do as exercise)**\n",
    "\n",
    "\\begin{align}\n",
    "\\mathrm{E}[Ax +b] &= A\\mathrm{E}[x] + b \\tag{SRG-3a}\\\\\n",
    "\\mathrm{cov}[Ax +b] &= A\\,\\mathrm{cov}[x]\\,A^T \\tag{SRG-3b}\n",
    "\\end{align}\n",
    "\n",
    "-  (The tag (SRG-3a) refers to the corresponding eqn number in Sam Roweis' Gaussian Identities notes.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Mean and Variance for the Sum of Two Variables\n",
    "\n",
    "For any distribution of $x$ and $y$ and $z=x+y$,\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathrm{E}[z] &= \\int_z z \\left[\\int_x p_x(x)p_y(z-x) \\,\\mathrm{d}{x} \\right] \\,\\mathrm{d}{z} \\\\\n",
    "&= \\int_x p_x(x) \\left[ \\int_z z p_y(z-x)\\,\\mathrm{d}{z} \\right] \\,\\mathrm{d}{x}  \\\\\n",
    "    &= \\int_x p_x(x) \\left[ \\int_{y^\\prime} (y^\\prime +x)p_y(y^\\prime)\\,\\mathrm{d}{y^\\prime} \\right] \\,\\mathrm{d}{x} \\notag\\\\\n",
    "&= \\int_x p_x(x) \\left( \\mathrm{E}[y]+x \\right) \\,\\mathrm{d}{x} \\notag\\\\\n",
    "    &= \\mathrm{E}[x] + \\mathrm{E}[y] \\qquad \\text{(always; follows from SRG-3a)}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Derive as an exercise that\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathrm{var}[z] &= \\mathrm{var}[x] + \\mathrm{var}[y] + 2\\mathrm{cov}[x,y] \\qquad \\text{(always, see SRG-3b)} \\notag\\\\\n",
    "    &= \\mathrm{var}[x] + \\mathrm{var}[y] \\qquad \\text{(if X and Y are independent)}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Review Probability Theory\n",
    "\n",
    "- Interpretation as a degree of belief, i.e. a state-of-knowledge, not as a property of nature.\n",
    "- We can do everything with only the **sum rule** and the **product rule**. In practice, **Bayes rule** and **marginalization** are often very useful for computing\n",
    "\n",
    "$$p(\\text{what-we-want}|\\,\\text{what-we-know})\\,.$$\n",
    "\n",
    "- Bayes rule $ p(\\theta|D) = \\frac{p(D|\\theta)p(\\theta)} {p(D)} $ is the fundamental rule for learning!\n",
    "\n",
    "- That's really about all you need to know about probability theory, but you need to _really_ know it, so do the exercises.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.10",
   "language": "julia",
   "name": "julia-0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
