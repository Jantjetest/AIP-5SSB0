{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Probability Theory?\n",
    "\n",
    "- Probability theory (PT) is the **theory of optimal processing of incomplete information**, and as such provides a quantitative framework for drawing conclusions from a finite (read: incomplete) data set.\n",
    "- Machine learning concerns drawing conclusions from data.\n",
    "- In general, nearly all interesting questions in machine learning can be stated in the following form (a conditional probability),\n",
    "\n",
    "$$\\p(\\text{whatever-we-want-to-know}\\, | \\,\\text{whatever-we-do-know})$$\n",
    "\n",
    "- For example\n",
    "  - Generate data predictions, $\\p(\\x_{\\text{future}}|\\x_{\\text{past}})$\n",
    "  - Classify a received data point, $\\p(\\class_k|\\x)$\n",
    "  - Compress data in an efficient way from $\\p(\\xv_n|\\x_{1:n-1})$\n",
    "\n",
    "- **Information theory** (`theory of log-probability`) provides a source coding view on machine learning that is consistent with probability theory (more in part-2). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.6",
   "language": "julia",
   "name": "julia 0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
