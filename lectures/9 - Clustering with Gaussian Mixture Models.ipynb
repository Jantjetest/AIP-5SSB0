{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  Limitations of Simple IID Gaussian Models\n",
    "\n",
    "Sofar, model inference was solved analytically, but we\n",
    "used strong assumptions\n",
    "- IID sampling, $p(D) = \\prod_n p(x_n)$\n",
    "- Simple Gaussian (or multinomial) PDFs, $p(x_n) \\sim \\mathcal{N}(x_n|\\mu,\\Sigma)$\n",
    "- Some limitations of Simple Gaussian Models with IID Sampling\n",
    "  1. What if the PDF is **multi-modal** (or is just not Gaussian in any other way)?\n",
    "  2. Covariance matrix $\\sigma$ has $D(D+1)/2$ parameters.\n",
    "    - This quickly becomes **a very large number** for increasing dimension $D$.\n",
    "  3. Temporal signals are often **not IID**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  Towards More Flexible Models\n",
    "\n",
    "-  What if the PDF is multi-modal (or is just not Gaussian in any other way)?\n",
    "  -   **Discrete latent** variable models (a.k.a. **mixture** models).\n",
    "    \n",
    "-  Covariance matrix $\\Sigma$ has $D(D+1)/2$ parameters. This quickly becomes very large for increasing dimension $D$.\n",
    "  -  **Continuous latent** variable models (a.k.a. **dimensionality reduction** models).\n",
    "    \n",
    "-  Temporal signals are often not IID.\n",
    "  -  Introduce **Markov dependencies** and **latent state** variable models.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "###  What if the Data are Not like This ...\n",
    "\\begin{center}\\includegraphics[height=8cm]{./figures/fig-2-class-data}\\end{center}\n",
    "\n",
    "\n",
    "###  ... but like This\n",
    "\\begin{center}\\includegraphics[height=8cm]{./figures/fig-unlabeled-data}\\end{center}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Unobserved Classes\n",
    "\n",
    "Consider again a set of observed data $D=\\{x_1,\\dotsc,x_N\\}$\n",
    "\n",
    "- This time we suspect that there are unobserved class labels that would help explain (or predict) the data, e.g.,\n",
    "  - the observed data are the color of living things; the unobserved classes are animals and plants.\n",
    "  - observed are wheel sizes; unobserved categories are trucks and personal cars.\n",
    "  - observed is an audio signal; unobserved classes include speech, music, traffic noise, etc.\n",
    "    \n",
    "Classification problems with unobserved classes are called **Clustering** problems. The learning algorithm needs to **discover the classes from the observed data**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Latent Variable Model Specification\n",
    " \n",
    "If the categories were observed as well, these data could be nicely modeled by the previously discussed generative classification framework.\n",
    "\n",
    "-  Introduce the 1-of-$K$ variable $z = (z_1,\\ldots,z_K)^T$ to represent the unobserved classes.\n",
    "  - NB: our notation is: $Y_k$ for observed targets; $Z_k$ for unobserved outputs.\n",
    "-  Use completely **equivalent model assumptions to linear generative classification**, (except now the class\n",
    "    labels $z_k$ are not observed),\n",
    "    \n",
    "\\begin{align}\n",
    "p(x_n) &= \\sum_{k=1}^K p(z_{nk}) \\, p(x_n|z_{nk})  \\\\\n",
    "\t&= \\sum_k \\pi_k \\mathcal{N}\\left(x_n|\\mu_k,\\Sigma_k \\right)\n",
    "\\end{align}\n",
    "\n",
    "This model is called a **Gaussian Mixture Model**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Gaussian Mixture Models\n",
    "GMMs are **universal approximators of densities** (as long as there are enough Gaussians of course)\n",
    "\n",
    "\\begin{figure}\n",
    "\\begin{center}\n",
    "\\includegraphics[width=10.5cm]{./figures/fig-ZoubinG-GMM-universal-approximation}\n",
    "\\end{center}\n",
    "The red curves show the (weighted) Gaussians; the blue curve the resulting density.\n",
    "\\end{figure}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.6",
   "language": "julia",
   "name": "julia 0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
