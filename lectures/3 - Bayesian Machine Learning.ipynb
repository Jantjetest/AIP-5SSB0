{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Machine Learning\n",
    "\n",
    "\n",
    "- Suppose that your task is to predict a `new' datum $x$, based on $N$  observations $D=\\{x_1,\\dotsc,x_N\\}$.\n",
    "\n",
    "- The Bayesian approach for this task involves three stages: \n",
    "  1. Model specification\n",
    "  1. parameter estimation (inference, learning)\n",
    "  1. Prediction (apply the model)\n",
    "  \n",
    "Let's discuss these three stages in a bit more detail:\n",
    "\n",
    "1. **Model specification**. \n",
    "Your first task is to propose a model with tuning parameters $\\theta$ for generating the data $D$.\n",
    "  - This involves specification of $p(D|\\theta)$ and a prior for the parameters $p(\\theta)$.\n",
    "  - _You_ choose the distribution $p(x|\\theta)$ based on your physical understanding of the data generating process.\n",
    "  - Note that, for independent observations $x_n$,\n",
    "$$ p(D|\\theta) = \\prod_{n=1}^N p(x_n|\\theta)$$\n",
    "  - _You_ choose the prior $p(\\theta)$ to reflect what you know about the parameter values before you see the data $D$.\n",
    "2. **Parameter estimation**.\n",
    "After model specification, use Bayes rule to find the posterior distribution for the parameters,\n",
    "$$\n",
    "p(\\theta|D) = \\frac{p(D|\\theta) p(\\theta)}{p(D)} \\propto p(D|\\theta) p(\\theta)\n",
    "$$  \n",
    "  - Note that there's **no need for you to design a _smart_ parameter estimation algorithm**. The only complexity lies in the computational issues.  \n",
    "  - [Q.]: What if I have more candidate models, say $\\mathcal{M} = \\{m_1,\\ldots,m_K\\}$?\n",
    "  - [A.]: Specify a prior $p(m)$ for the models and use Bayes again to absorb what we can learn from the data,\n",
    "$$ \n",
    "p(m|D) = \\frac{p(D|m) p(m)}{p(D)} \\propto p(D|m)p(m)\n",
    "$$\n",
    "  - This \"recipe\" works only if the RHS factors can be evaluated; this is what machine learning is about.\n",
    "$\\Rightarrow$ **Machine learning is easy, apart from computational details:)**\n",
    "3. **Prediction**. \n",
    "Given the data $D$, our knowledge about the yet unobserved datum $x$ is captured by\n",
    "\n",
    "$$\n",
    "p(x|D) = \\int p(x,\\theta|D) \\,\\mathrm{d}\\theta = \\int p(x|\\theta) p(\\theta|D) \\,\\mathrm{d}\\theta\n",
    "$$\n",
    "\n",
    "  - Again, no need to invent a special prediction algorithm. Probability theory takes care of all that. The complexity of prediction is just computational: how to carry out the marginalization over $\\theta$.\n",
    "  \n",
    "  - What did we learn from $D$? Without access to $D$, we would predict new observations through\n",
    "\n",
    "$$\n",
    "p(x) = \\int p(x,\\theta) \\,\\mathrm{d}\\theta = \\int p(x|\\theta) p(\\theta) \\,\\mathrm{d}\\theta\n",
    "$$\n",
    "\n",
    "  - Remaining problem: How good really were our model assumptions $p(x|\\theta)$ and $p(\\theta)$?  More on this in part 2 (Tjalkens).  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning and the Scientific Method Revisited\n",
    "\n",
    "- Bayesian probability theory provides a unified framework for information processing (and even the Scientific Method).\n",
    "\n",
    "\\includegraphics[width=12.5cm]{./figures/fig-Bayesian-scientific-method}\n",
    "%\\caption{The Scientific Method}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### EXAMPLE: Coin Tossing\n",
    "\n",
    "- Observe a sequence of $N$ coin tosses with $n$ heads. What's the probability that heads ($h$) comes up next?\n",
    "\n",
    "1. **Model Specification** \n",
    "\n",
    "  - Assume a Bernoulli variable $p(x_n=h|\\mu)=\\mu$, leading to\n",
    "\n",
    "$$   \n",
    "p(D|\\mu) = \\prod_{n=1}^N p(x_n|D) = \\mu^n (1-\\mu)^{N-n}\n",
    "$$\n",
    "\n",
    "  - Also, assume prior belief is governed by a **beta distribution**\n",
    "\n",
    "$$\n",
    "p(\\mu) = \\mathcal{B}(\\mu|\\alpha,\\beta) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\mu^{\\alpha-1}(1-\\mu)^{\\beta-1}\n",
    "$$\n",
    "\n",
    "\n",
    "  - NB: The beta-distribution is a _binomial_ over the continuous range $[0,1]$.\n",
    "  - $\\alpha$ and $\\beta$ are called **hyperparameters**, since they parameterize the distribution for another parameter ($\\mu$). E.g., $\\alpha=\\beta=1$ (uniform), $\\alpha=\\beta=0.5$ (Jeffreys prior), $\\alpha=\\beta=0$ (improper Laplace prior)\n",
    "  - If $\\alpha,\\beta$ are integers, then $\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)(\\Gamma(\\beta)} = \\frac{(\\alpha+\\beta)!}{\\alpha!\\,\\beta!}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Coin toss example (2): Parameter estimation\n",
    "\n",
    "- Infer posterior PDF over $\\mu$ through Bayes rule\n",
    "\n",
    "\\begin{align}\n",
    "p(\\mu|D) &= \\frac{p(D|\\mu)p(\\mu|\\alpha,\\beta)}{\\int_0^1 p(D|\\mu)p(\\mu|\\alpha,\\beta)\\,\\mathrm{d}\\mu } \\\\ \n",
    "        &= \\frac{\\mu^n (1-\\mu)^{N-n} \\times \\mu^{\\alpha-1}(1-\\mu)^{\\beta-1}}{\\int_0^1 \\mu^n (1-\\mu)^{N-n}\\mu^{\\alpha-1}(1-\\mu)^{\\beta-1} \\,\\mathrm{d}\\mu} \\\\\n",
    "        &= \\frac{(N+\\alpha+\\beta-1)!}{(n+\\alpha-1)!(N-n+\\beta-1)!}  \\mu^{n+\\alpha-1} (1-\\mu)^{N-n+\\beta-1}\n",
    "\\end{align}\n",
    "\n",
    "where we used the formula for the _beta integral_ $$\\int_0^1 x^p (1-x)^q \\,\\mathrm{d}x = \\frac{p!q!}{(p+q+1)!}$$\n",
    "\n",
    "- Essentially, **here ends the machine learning activity**\n",
    "\n",
    "- Note: $p(\\mu|D) \\sim \\mathcal{B}(\\mu|\\,n+\\alpha, N-n+\\beta)$ is again beta, or\n",
    "\n",
    "$$\n",
    "\\text{beta} \\propto \\text{binomial} \\times \\text{beta}\\notag\n",
    "$$\n",
    "\n",
    "- The Beta distribution is a **conjugate prior** for the Binomial distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coin Toss Example (3): Prediction\n",
    "\n",
    "- Marginalize over the parameter posterior to get the predictive PDF, given the data $D$,\n",
    "\n",
    "\\begin{align}\n",
    "p(h|D)  &= \\int_0^1 p(h|\\mu)p(\\mu|D) \\,\\mathrm{d}\\mu \\\\\n",
    "  &= \\frac{(N+\\alpha+\\beta-1)!}{(n+\\alpha-1)!(N-n+\\beta-1)!}  \\int_0^1 \\mu \\times  \\mu^{n+\\alpha-1} (1-\\mu)^{N-n+\\beta-1} \\,\\mathrm{d}\\mu  \\\\\n",
    "  &= \\frac{n+\\alpha}{N+\\alpha+\\beta} \\qquad \\mbox{(a.k.a. Laplace rule)}\\hfill\n",
    "\\end{align}\n",
    "\n",
    "- For large $N$, $p(h|D)=(n+\\alpha)/(N+\\alpha+\\beta)$ goes to relative frequency $n/N$.\n",
    "- Example: for uniform prior ($\\alpha=\\beta=1$) and $D=\\{hthhtth\\}$, we get\n",
    " $$  p(h|D)=\\frac{n+1}{N+2} = \\frac{4+1}{7+2} = \\frac{5}{9}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coin Toss Example: What did we learn?\n",
    "\n",
    "- What did we learn from the data? Before seeing any data, we think that $p(h)=\\left. p(h|D) \\right|_{n=N=0} = \\alpha / (\\alpha + \\beta)$ .\n",
    "- After the $N$ coin tosses, we think that \n",
    "$$\n",
    "p(h|D) = (n+\\alpha)/(N+\\alpha+\\beta)\n",
    "$$\n",
    "- Note the following decomposition\n",
    "\n",
    "\\begin{align}\n",
    "    p(h|\\,D,\\alpha,\\beta) &= (n+\\alpha)/(N+\\alpha+\\beta) \\\\\n",
    "        &= \\frac{n}{N+\\alpha+\\beta} + \\frac{\\alpha}{N+\\alpha+\\beta} \\\\\n",
    "        &= \\frac{N}{N+\\alpha+\\beta}\\cdot \\frac{n}{N} + \\frac{\\alpha+\\beta}{N+\\alpha+\\beta} \\cdot \\frac{\\alpha}{\\alpha+\\beta} \\\\\n",
    "        &= \\underbrace{\\frac{\\alpha}{\\alpha+\\beta}}_{prior} + \\underbrace{\\frac{N}{N+\\alpha+\\beta}}_{gain}\\cdot ( \\underbrace{\\frac{n}{N}}_{MLE} - \\underbrace{\\frac{\\alpha}{\\alpha+\\beta}}_{prior} )\n",
    "    \\end{align}\n",
    "\n",
    "- Note that estimate lies between prior and MLE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Evolution of $p(\\mu|D)$ for the Coin Toss\n",
    "\n",
    "\\begin{figure}[h]\\centering\n",
    "\\includegraphics[height=5cm]{./figures/fig-coin-toss-posterior}\n",
    "\\end{figure}\n",
    "\n",
    "- Evolution of posterior prob $p(\\mu|D)$ after increasing number of coin tosses. Left-upper solid curve for uniform prior; dashed curve for Gaussian prior \n",
    "\n",
    "$\\Rightarrow$ **with more data, the relevance of the prior diminishes**.\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### From Posterior to Point-Estimate\n",
    "Sometimes we want just one 'best' parameter (vector), rather than a posterior distribution over parameters. Why?\n",
    "\n",
    "- Recall Bayesian prediction\n",
    "$$\n",
    "p(x|D) = \\int p(x|\\theta)p(\\theta|D)\\,\\mathrm{d}{\\theta}\n",
    "$$\n",
    "\n",
    "- If we approximate posterior $p(\\theta|D)$ by a delta function for one 'best' value $\\hat\\theta$, then the predictive distribution collapses to\n",
    "\n",
    "$$\n",
    "p(x|D)= \\int p(x|\\theta)\\delta(\\theta-\\hat\\theta)\\,\\mathrm{d}{\\theta} = p(x|\\hat\\theta)\n",
    "$$\n",
    "\n",
    "- This is the model $p(x|\\theta)$ evaluated at $\\theta=\\hat\\theta$.\n",
    "- Note that $p(x|\\hat\\theta)$ is much easier to evaluate than the integral for full Bayesian prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Some Well-known Point-Estimates\n",
    "\n",
    "1. **Bayes estimate**$$\n",
    "\\hat \\theta_{bayes}  = \\int \\theta \\, p\\left( \\theta |D \\right)\n",
    "\\d{\\theta}\n",
    "$$\n",
    "\n",
    "  - (homework). Proof that the Bayes estimate minimizes the expected mean-square error, i.e., proof that\n",
    "$$\n",
    "\\hat \\theta_{bayes} = \\arg\\min_{\\hat \\theta} \\int_\\theta (\\hat \\theta -\\theta)^2 p \\left( \\theta |D \\right) \\,\\mathrm{d}{\\theta}\n",
    "$$\n",
    "\n",
    "2. **Maximum A Posteriori** (MAP) estimate \n",
    "$$\n",
    "\\hat \\theta_{\\text{map}}=  \\arg\\max _{\\theta} p\\left( \\theta |D \\right) =\n",
    "\\arg \\max_{\\theta}  p\\left(D |\\theta \\right) \\, p\\left(\\theta \\right)\n",
    "$$\n",
    "\n",
    "3. **Maximum Likelihood** (ML) estimate\n",
    "\n",
    "$$\n",
    "\\hat \\theta_{ml}  = \\arg \\max_{\\theta}  p\\left(D |\\theta\\right)\n",
    "$$\n",
    "\n",
    "  - Note that Maximum Likelihood is MAP with uniform prior\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning with Maximum Likelihood Estimation\n",
    "\n",
    "Consider the task: predict a datum $x$ from an observed data set $D$.\n",
    "1. Model specification. \n",
    "  - Choose a model $m$ with parameters $\\theta \\in \\Theta$ and the data generating distribution $$p(x|\\theta,m)$$. (No need for priors).\n",
    "2. Learning \n",
    "  - By Maximum Likelihood (ML) optimization,\n",
    "$$ \n",
    "    \\hat \\theta  = \\arg \\max_{\\theta}  p(D |\\theta,m)\n",
    "$$\n",
    "3. Prediction. \n",
    " - Easy through\n",
    "$$ \n",
    "    p(x|D) =  p(x|\\hat\\theta,m)\n",
    "$$\n",
    "\n",
    "- Note that this is a computationally easy approximation to the Bayesian approach. What is the price?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Card on Maximum Likelihood Estimation\n",
    "- Maximum Likelihood (ML) is MAP with uniform prior, or MAP is 'penalized' ML\n",
    "$$\n",
    "\\hat \\theta_{map}  = \\arg \\max _\\theta  \\{ \\overbrace{\\log\n",
    "p\\left( D|\\theta  \\right)}^{\\mbox{log-likelihood}} + \\overbrace{\\log\n",
    "p\\left( \\theta \\right)}^{\\mbox{penalty}} \\}\n",
    "$$\n",
    "- (good!). Works rather well if we have a lot of data because the influence of the prior diminishes with more data.\n",
    "- (bad). Cannot be used for model comparison. E.g. best model does generally not correspond to largest likelihood (see part-2, Tjalkens).\n",
    "- (good). Computationally often do-able. Useful fact (since $\\log$ is monotonously increasing):\n",
    "$$\\arg\\max_\\theta \\log p(D|\\theta) =  \\arg\\max_\\theta p(D|\\theta)$$\n",
    "\n",
    "$\\Rightarrow$ **ML estimation is an approximation to Bayesian learning**, but in the face of lots of available data for good reason a very popular learning method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.6",
   "language": "julia",
   "name": "julia 0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
